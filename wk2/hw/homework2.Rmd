---
title: Week 2 Homework
author: "Author: Laura Wooten"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`" 
output: 
  html_notebook:
    code_folding: hide
    number_sections: true
---

> For this homework assignment, you will need to download a data set from the UCI machine learning repository. Separate the data set you downloaded into two groups by the outcome variable that is being studied. For most of the data sets in the UCR machine learning repository, most of the time, this will be categorical variable in the “last column” in the data set. If more than one outcome was studied, use the one with the greatest number of records. Then do the following:

UCI machine learning repo site was down - using Maternal Health Risk Data Set that you sent me via email.
Steps:  
1. read in csv file  
2. preview data, how many levels/outcomes for variable being explored?   
3. Create 2 groups: low-risk and high risk 
```{r}
MatRisk <- read.csv("Maternal Health Risk Data Set.csv")
#preivew
MatRisk[1:5,]
class(MatRisk)
unlist(lapply(MatRisk[,1:7],class))
#Change $RiskLevel from chr to factor so can assess levels
MatRisk$RiskLevel <- as.factor(MatRisk$RiskLevel)
class(MatRisk$RiskLevel)
#check levels of  
risk.levels <- levels(MatRisk$RiskLevel); risk.levels
```
```{r eval=FALSE, include=FALSE}
#which level has greatest # records? - dont need anymore
max.obs <- 0
most.frequent <- NULL

for (i in risk.levels) {
  Nobs <- sum(MatRisk$RiskLevel == i)  # Count the # of observations for each level
  if (Nobs > max.obs) {
    max.obs <- Nobs
    most.frequent <- i  # Store the level with the greatest frequency
  }
}
print(paste('Level with greatest number of records:', most.frequent))
```

```{r}
#Separate into two groups
lowrisk <- MatRisk[MatRisk$RiskLevel == 'low risk',]; #select all columns for rows whose risklevel is low
highrisk <- MatRisk[MatRisk$RiskLevel == 'high risk',]; #select all other rows
rm(list=setdiff(ls(), c("lowrisk", "highrisk", "MatRisk")))
```


> 1. 20 points Perform normality tests for each data feature. At a minimum, these normality tests should include a Shapiro-Wilks normality test along with a qq-plot. Describe the results of these tests.

```{r eval=FALSE, include=FALSE}
for (feature.name in names(lowrisk)[1:6]){ #column 7 is non numerical - leave out
  feature.vec <- lowrisk[[feature.name]] #column as a vector
  test <- shapiro.test(feature.vec)
  if(test$p.value < 0.05){
    distribution <- "Not normally distributed"
  }else{
    distribution <- "Normally distributed"
  }
  print(paste(feature.name, ":", distribution))
  
  #plot qq
  qqnorm(feature.vec, main= paste('QQ-Plot of', feature.name))
  qqline(feature.vec, col= "blue")
  
  #histogram
  hist(feature.vec, main = paste('Histogram of', feature.name))
}
# shapiro.test(df$column)
# 
# # create qq plot of 1st column in df
# qqnorm(df[,1], main= "QQ plot of column")
# qqline(df[,1], col= "red")

```
I was confused as to whether or not to implement this using the entire data set or the partitioned data set, so I did both just to see the differences.   
**Entire data set `MatRisk`**

```{r}
#using entire dataset
# First loop: Print only textual results
for (feature.name in names(MatRisk)[1:6]){
  feature.vec <- MatRisk[[feature.name]]
  test <- shapiro.test(feature.vec)
  
  if(test$p.value < 0.05){
    distribution <- "Not normally distributed"
  }else{
    distribution <- "Normally distributed"
  }
  
  print(paste(feature.name, ":", distribution))
}

# Second loop: Generate plots

for (feature.name in names(MatRisk)[1:6]){
  feature.vec <- MatRisk[[feature.name]]
  
  par(mfrow = c(1, 2)) #plot side by side
  # QQ-plot
  qqnorm(feature.vec, main = paste("QQ-Plot of", feature.name))
  qqline(feature.vec, col = "blue")
  
  # Histogram
  hist(feature.vec, main = paste("Histogram of", feature.name), xlab= "Recorded Value", col="lightblue")
  
  
  
}
```

**Using partitioned data set** 
```{r}
# First loop: Print only textual results
for (feature.name in names(lowrisk)[1:6]){
  feature.vec <- lowrisk[[feature.name]]
  test <- shapiro.test(feature.vec)
  
  if(test$p.value < 0.05){
    distribution <- "Not normally distributed"
  }else{
    distribution <- "Normally distributed"
  }
  
  print(paste(feature.name, ":", distribution))
}

# Second loop: Generate plots

for (feature.name in names(lowrisk)[1:6]){
  feature.vec <- lowrisk[[feature.name]]
  
  par(mfrow = c(1, 2)) #plot side by side
  # QQ-plot
  qqnorm(feature.vec, main = paste("QQ-Plot of", feature.name))
  qqline(feature.vec, col = "blue")
  
  # Histogram
  hist(feature.vec, main = paste("Histogram of", feature.name), xlab= "Recorded Value", col="lightblue", border= "white")
  
  
  
}



```

The Shapiro tests for each column indicate that this data is not normalized, meaning there is more than just chance that the values are different between the outcome variables. When looking at the QQ-plots they don't follow the theoretical line that indicates a normal distribution, and histograms also don't appear to be in a bell shaped curve. The only plots that look like they could be close to a normal distribution is data for HeartRate, but the Shapiro tests still come back as p < 0.05, so we can assume that even though this one is close, to treat it as a non normalized data. 

---
> 2. 20 points Create a box plot with each column of the data set on the x-axis, the value of the columns on the y-axis, and colored by the outcome that is being studied.

```{r}
#I think?
#boxplot(highrisk$Age~highrisk$RiskLevel, ylab = "value name") Uses same df. my results have been separated into to data frames


par(mfrow = c(2, 3)) # Arrange plots in a 2x3 grid

boxplot(highrisk$Age, lowrisk$Age, names = c("High Risk", "Low Risk"), main = "Age by RiskLevel", col = c("red", "blue"))
boxplot(highrisk$BS, lowrisk$BS, names = c("High Risk", "Low Risk"), main = "BS by RiskLevel", col = c("red", "blue"))
boxplot(highrisk$BodyTemp, lowrisk$BodyTemp, names = c("High Risk", "Low Risk"), main = "BodyTemp by RiskLevel", col = c("red", "blue"))

boxplot(highrisk$HeartRate, lowrisk$HeartRate, names = c("High Risk", "Low Risk"), main = "HeartRate by RiskLevel", col = c("red", "blue"))
boxplot(highrisk$SystolicBP, lowrisk$SystolicBP, names = c("High Risk", "Low Risk"), main = "Systolic BP by RiskLevel", col = c("red", "blue"))
boxplot(highrisk$DiastolicBP, lowrisk$DiastolicBP, names = c("High Risk", "Low Risk"), main = "DistolicBP by RiskLevel", col = c("red", "blue"))

```
Would have used the "~" sign to plot each column of data against RiskLevel like in the lecture notes (eg `boxplot(MatRisk$Age ~ MatRisk$RiskLevel, col=c(red, blue))`), but instructions said to separate the data into two distinct groups before continuing. The box plots reveal clear differences between the low-risk and high-risk maternal groups. The average values for age, blood sugar (BS), systolic blood pressure, and diastolic blood pressure are all higher for the high-risk group compared to the low-risk group. Moreover, the range of values is wider in the high-risk category, indicating more variability in these health measures. In contrast, mothers in the low-risk group consistently stay within healthy norms. This suggests that high-risk outcomes are influenced by a broader spectrum of factors. 

> 3. 20 points Perform hypothesis tests comparing paired columns of the partitioned data set. You will need to determine which hypothesis test to perform based on your normality test results.

The normality tests results indicate that data for each column is not parametrically distributed, therefore I have used a Mann-Whitney U Test to perform hypothesis testing for each column. My understanding of this question is that I need to compare each feature between outcome, for example does the Age of patients with high risk statistically differ to the distribution of ages of patients with low risk. To do this I have marked paired = False as an argument in the wilcox.test() function because the paired argument here is referring to measurements taken for that sample (ie that patient) which would be analyzing results from within the same row of a dataframe.

```{r}
for (feature.name in names(lowrisk)[1:6]){
  hr.feature <- highrisk[[feature.name]]
  lr.feature <- lowrisk[[feature.name]]
  test.result <- wilcox.test(hr.feature, lr.feature, conf.int =T, paired = F, formula="lhs" )
  
  print(paste("Mann-Whitney U Test for:", feature.name))
  print(test.result)
  
        
}
```
The p-values for each feature are less than 0.05, meaning that we reject the null hypothesis and accept the alternate hypothesis that states that the differences in each each feature by outcome do not come from the same distribution, and therefore are not occurring by chance. This indicates that there is legitimate reasoning behind the differences seen for each feature and they are somehow connected/specific to the outcome being studied, in this case maternal risk. 


> 4. 40 points Select a column of the data set with the greatest variance and overlap between outcome groups. Take a random sampling of the data with different sample sizes (say, 10, 15, 20 samples) from both groups. Then perform a hypothesis test between both groups and retain the p-value. Repeat this process 1000 times. For each iteration, save the p-values in a vector called Pvals. Then plot the distribution of significance tests for each re-sampling. Repeat this process with the column with the least variance and overlap between outcome groups. Explain the results and the differences between both simulations.


From the box plots, it appears that the column with the greatest variance and overlap is DiastolicBP. This is visually apparent looking at the overlap between the IQR and outliers, as well as the stretch of each in either direction to view the variance. However if we wanted to quantify the difference to know for sure we could use the following:

Take a random sampling:
```{r eval=FALSE, include=FALSE}
h.diastolic <- highrisk$DiastolicBP
l.diastolic <- lowrisk$DiastolicBP
set.seed(12)


#select random samples
h.10 <- sample(h.diastolic[!is.na(h.diastolic)], 10) #random sample of 10
l.10 <- sample(l.diastolic[!is.na(l.diastolic)], 10) #random sample of 10
h.15 <- sample(h.diastolic[!is.na(h.diastolic)], 15) #random sample of 15
l.15 <- sample(l.diastolic[!is.na(l.diastolic)], 15) #random sample of 15
h.20 <- sample(h.diastolic[!is.na(h.diastolic)], 20) #random sample of 20
l.20 <- sample(l.diastolic[!is.na(l.diastolic)], 20) #random sample of 20

#calculate variance of each group
vh.10 <- var(h.10)
vl.10 <- var(l.10)
vh.15 <- var(h.15)
vl.15 <- var(l.15)
vh.20 <- var(h.20)
vl.20 <- var(l.20)

var.h <- c(vh.10, vh.15, vh.20)
var.l <- c(vl.10, vl.15, vl.20)

test.x <- wilcox.test(var.h, var.l); test.x
```




```{r}
# create a function that creates a single p value by performing comparisons of variances from random samples of each output group

variance.pvalue <-  function(high.data, low.data, samplesizes){
    #create vectors to store var
  high.var <- c()
  low.var <- c()
  
  #loop through sample size
  for (i in 1:length(samplesizes)){
    size <- samplesizes[i] #current sample size
    #take random samples of the current sample size
    high.sample <- sample(high.data[!is.na(high.data)], size)
    low.sample <- sample(low.data[!is.na(low.data)], size)
    
    #calc vars
    high.var[i] <- var(high.sample)
    low.var[i] <- var(low.sample)
  }
  #MannW U test on all variances
  w.test <- wilcox.test(high.var, low.var)
    
  w.test$p.value

}
```

```{r}
#create vectors
h.diastolic <- highrisk$DiastolicBP
l.diastolic <- lowrisk$DiastolicBP

#call function
initial.pvalue <- variance.pvalue(h.diastolic, l.diastolic, c(10, 15, 20));initial.pvalue
```



```{r}
#rpt 1000 times, save p-values
Pvals <- c()

#loop 1000 times
for (i in 1:1000){
  Pvals[i] <- variance.pvalue(h.diastolic, l.diastolic, c(10, 15, 20))
}
summary(Pvals)
# histogram of p-values
hist(Pvals, breaks = 30, col = "blue", main = "Distribution of P-values",
     xlab = "P-value", ylab = "Frequency")

```




Repeat this with least variance and overlap column: 
Choosing the column with the least variance and overlap is difficult for this data set. Blood sugar (BS) has the least overlap, but the high risk still has a large variance, SystolicBP also has a fairly wide variance and little overlap, while HeartRate has very little variance but a great deal of overlap. I'm going to play with BS.

```{r}
high.BS <- highrisk$BS; high.BS[1:10]
low.BS <- lowrisk$BS; low.BS[1:10]

BP.Pvals <- c()
for (i in 1:100){
  BP.Pvals[i] <- variance.pvalue(high.BS, low.BS, c(10, 15, 20))
}
summary(BP.Pvals)
print(BP.Pvals)
hist(BP.Pvals, breaks = 30, col = "blue", main = "Distribution of P-values",
     xlab = "P-value", ylab = "Frequency")

```
This result certainly confused me. I was looking at the original box plots and saw that there was very little overlap, and the variances were considerably different, so having a result of p=0.1 for every sampling, really made not sense to me. Then I started thinking about the Mann-Whittney U test, and that it handles non-parametric raw data. What we are dealing with in this hypothesis test is no longer the raw data, but the variance statistical set of each sample data, and to a large n value. Therefore, due to the large sample sized I realized the central limit therom came into play and I should indeed be able to use the t-test here, even though the raw data is not Gaussian, as variances may actually be similar to normalized data. See below the altered function for a t-test instead:

```{r}
# Function to perform t-test on resampled variances
t_test_variance <- function(high.data, low.data, sample_sizes) {
  
  high_variances <- c()
  low_variances <- c()
  
  # Loop through sample sizes
  for (i in 1:length(sample_sizes)) {
    size <- sample_sizes[i]  # Current sample size
    
    # Take random samples
    high_sample <- sample(high.data[!is.na(high.data)], size)
    low_sample <- sample(low.data[!is.na(low.data)], size)
  
    high_variances[i] <- var(high_sample)
    low_variances[i] <- var(low_sample)
  }
  
  # Perform t-test on the variances
  t_test <- t.test(high_variances, low_variances, alternative = "two.sided", var.equal = TRUE) #two sided as we are looking for a difference in either direction, not one is greater than the other.
  
  # Return the p-value
  return(t_test$p.value)
}

##blood sugar
# Run the t-test  1000 times
t_test_pvals <- c()  # Initialize vector to store p-values

for (i in 1:1000) {
  t_test_pvals[i] <- t_test_variance(high.BS, low.BS, sample_sizes = c(10, 15, 20))
}

hist(t_test_pvals, breaks = 30, col = "blue", main = "Distribution of BS P-values (1000 Iterations)",
     xlab = "P-value", ylab = "Frequency")
abline(v = 0.05, col = "red", lwd = 2)  # Add significance line
#___

#diastolic
t2_pvals <- c()
for (i in 1:1000) {
  t2_pvals[i] <- t_test_variance(h.diastolic, l.diastolic, sample_sizes = c(10, 15, 20))
}
hist(t2_pvals, breaks = 30, col = "blue", main = "Distribution of DiastolicBP P-values (1000 Iterations)",
     xlab = "P-value", ylab = "Frequency")
abline(v = 0.05, col = "red", lwd = 2)  # Add significance line
```
So this is more like it! Woop!  
Once I saw what I was expecting with the lower variance/overlap column, I called the new function with the original high variance/high overlap column. I know at this stage I could have removed my initial function and results, but it hurt my soul slightly to just discard several hours of work I put into trying to understand and work on this question, and I wanted to show that I learnt a lot from this exercise.  
Comparing the two histograms here:  
We can see that in the BS histogram there are still p-values above the threshold, but majority are below 0.05, indicating that we can reject the null hypothesis and conclude that the difference in variance here is not due to chance, and that there are legitimate differences in variance based on the outcome. In the histogram of DiastolicBP however, majority of p-values lie above the level of significance. This is not surprising as the variance was very similar between the two outcomes even though the means were different. Speaking of which, if we performed these hypothesis tests using mean instead of variance, I believe we would encounter different results again, as variance is looking at the spread of values in each sample over 1000 trials, where mean is just the average. 

